\documentclass{acmsiggraph}                     % final
%\documentclass[annualconference]{acmsiggraph}  % final (annual conference)
%\documentclass[review]{acmsiggraph}            % review
%\documentclass[widereview]{acmsiggraph}        % wide-spaced review
%\documentclass[preprint]{acmsiggraph}          % preprint

%% Uncomment one of the five lines above depending on where your paper is
%% in the conference process. ``review'' and ``widereview'' are for review
%% submission, ``preprint'' is for pre-publication, and ``final'' is for
%% the version to be printed. The ``final'' variant will accept the 
%% ``annualconference'' parameter, which changes the height of the space
%% left clear for the ACM copyright information.

%% The 'helvet' and 'times' packages define the typefaces used for
%% serif and sans serif type in this document. Computer Modern Roman 
%% is used for mathematics typesetting. The scale factor is set to .92
%% to bring the sans-serif type in line with the serif type.

\usepackage[scaled=.92]{helvet}
\usepackage{times}

%% The 'graphicx' package allows for the inclusion of EPS figures.

\usepackage{graphicx}

%% use this for zero \parindent and non-zero \parskip, intelligently.

\usepackage{parskip}

%% Optional: the 'caption' package provides a nicer-looking replacement
%% for the standard caption environment. With 'labelfont=bf,'textfont=it',
%% caption labels are bold and caption text is italic.

\usepackage[labelfont=bf,textfont=it]{caption}

%% If you are submitting a paper to the annual conference, please replace 
%% the value ``0'' below with the numeric value of your OnlineID. 
%% If you are not submitting this paper to the annual conference, 
%% you may safely leave it at ``0'' -- it will not be included in the output.

\onlineid{0}

%% Paper title.

\title{A Study of Immersion Factors Using an Augmented Reality Simulation}

%% Author and Affiliation (single author).

%%\author{Roy G. Biv\thanks{e-mail: roy.g.biv@aol.com}\\Allied Widgets Research}

%% Author and Affiliation (multiple authors).

\author{
Roy G. Biv\thanks{e-mail: roy.g.biv@aol.com}\\ Starbucks Research %
\and Ed Grimley\thanks{e-mail:ed.grimley@aol.com}\\Nigel Mansell\thanks{nigelf1@msn.com}\\ Grimley Widgets, Inc. %
\and Martha Stewart\thanks{e-mail:martha.stewart@marthastewart.com}\\ Martha Stewart Enterprises \\ Microsoft Research
}

%% Keywords that describe your work.

\keywords{
%radiosity, global illumination, constant time
}

%%%%%% START OF THE PAPER %%%%%%

\begin{document}

%\teaser{
%  \includegraphics[width=1.5in]{sample.eps}
%  \caption{Lookit! Lookit!}
%}

%% The ``\maketitle'' command must be the first command after the
%% ``\begin{document}'' command. It prepares and prints the title block.

\maketitle

%% Abstract section.

\begin{abstract}

Augmented reality (AR) systems are expensive.  It is worth studying the effects of level of immersion in AR systems in order to determine an appropriate cost to benefit ration.  This is an AR study, simulated using a virtual reality (VR), to examine the effects of level of immersion in AR.  We analyze a tracking task where the AR interface provides x-ray vision to help track a moving target.  We varied the field of view of the AR display, as well as the reliability of the head tracker.  In low reliability conditions, we simulate tracker failure by disabling the augmented view of the scene for brief periods.  Our study gives insight into the effect of head tracker reliability on user performance in a tracking task, as well as the relationship between reliability and field of view in an AR system.

\end{abstract}

%% ACM Computing Review (CR) categories. 
%% See <http://www.acm.org/class/1998/> for details.
%% The ``\CRcat'' command takes four arguments.

\begin{CRcatlist}
%  \CRcat{K.6.1}{Management of Computing and Information Systems}{Project and People Management}{Life Cycle};
%  \CRcat{K.7.m}{The Computing Profession}{Miscellaneous}{Ethics}
\end{CRcatlist}

%% The ``\keywordlist'' command prints out the keywords.
\keywordlist

\section{Introduction}

%% The ``\copyrightspace'' command must be the first command after the 
%% start of the first section of the body of your paper. It ensures the
%% copyright space is left at the bottom of the first column on the first
%% page of your paper.

%% \copyrightspace

Augmented Reality systems may be used to simulate x-ray vision \cite{1383060}.  The ability to see through solid objects has applications in various fields ranging from engineering and architecture to military or search-and-rescue operations.  Unfortunately, implementing x-ray vision is not a trivial task.  AR systems have cost issules, including those pertaining to level-of-immersion.  For example, what is the ideal augmented field of view (FOV) for a given scenario?  Other issues relate to tracking the objects in the x-ray view, such as GPS dropout errors \cite{4079263}, where tracking is temporarily lost.

In this paper, we study the effects of varying augmented FOV along with object-tracking dropouts.  By using an AR simulation built with virtual reality, it is possible to simulate the tracking dropouts, which would otherwise be difficult or impossible to replicate.  The simulation is a tracking task, where the participant is placed inside a virtual room and visually follows a person outside, walking an unpredictable path.  We wish to answer the following questions.  What effect does varying the augmented FOV have on user tracking performance?  What effect do different dropout lengths have on performance?  What are the interactions between these two variables?

\section{Related Work}

Livingston and Ai studied the effects of various sources of registration error with an AR simulation similar to our own \cite{4637329}.  Here, participants tracked a virtual car moving throughout a real environment, with a white box representing an augmented view of the car's location.  A white box was continuously visible, even when the car itself was occluded by a building in the environment.  Other virtual cars and their associated white boxes acted as distractors.  At specific times during the experiment, the simulation would freeze and the participant was asked to align the center of their view (indicated by cross-hairs) on the location of the correct car and press a key.  While the effects of several types of error were studied in this work, the effect of registration dropouts was not examined.

Bane and H\"{o}llerer propose a set of AR tools for virtual x-ray vision \cite{1383060}.  Various augmented views are presented, each attempting to overcome the "Superman's X-ray vision" problem of presenting too much AR information to the user.  The toolset's usefulness is illustrated with an example of an outdoors user viewing the contents of a nearby building.

% TODO: add discussion of validity of AR simulation w/ citations

%other studies which vary AR fov, tracking failures?

\section{AR Simulation}

Our experiment involves a tracking task which uses an augmented reality interface to allow people to be tracked behind walls.  A participant stands in the middle of a square room with doors and windows on all sides.  Outside of the room, people are walking around the building.  The target person to be tracked is visually distinguishable by a large black top hat.  The augmented reality interface overlays a translucent red rectangle on each person, which is visible even when the person is occluded by a wall.  However, the target person's overlay is not different from any other person's overlay; the target is only identifiable when visible through a window or a door.

To actually run this experiment using a true augmented reality system would be difficult.  Many confederates would be needed to walk around the room, and their movements would need to be accurately reproduced for each new participant.  Also, the confederates would need to be continously tracked for the augmented overlays to be displayed.  Instead, we simulated the experiment setup in a completely virtual environment.

By simulating augmented reality, we are freed from the current restrictions of tracking and display technology.  Using a simulated environment also makes the experiment more controllable, and thus more easily reproduced.

\section{Experimental Design}

The design of the experiment is based around the idea that a task should have straightforward quantitative results.  Also, the task should be reasonably simple so as not to frustrate the participants.  Added challenges were that the task should be generic so as to be generizable, yet grounded in reality (i.e. not an abstract world), to enhance participant familiarity with the AR task.

We developed a tracking scenario, where the user is asked to visually track a virtual person as he moves around the scene.  The participant is centered inside a room with various doors and windows giving a view to the outside world.  They may change their orientation as the please, but not change position (3 degrees of freedom).  The user's view to the tracked virtual person may be occluded at any time by the walls of the building.  The augmented view element is composed of red marker rectangles indicating the location of the tracked person and other virtual people.

\begin{figure}[t]
	\centering
	\includegraphics[width=3in]{figures/augmentedroom.png}
	\caption{Overhead view of virtual room (approx. measure).  Participant is stationary in the center of the room, with initial orientation along ``user view'' arrow.  Top-hat's initial position is outside the front doorway, directly in the participant's view.}
\end{figure}

Participants are presented a view of the scene through a head-mounted display helmet with orientation tracking.  The tracking overlays are augmented on top of the original image to form the simulated augmented reality view.

The parameters of our experiment are divided between the ``real'' immersion factors, such as the field of view of the HMD, and the ``augmented'' immersion factors, such as the field of view of the simulated AR display, and the performance of the head tracker.  We introduce periods of tracking failure, where the augmented overlays disappear, to simulate the effect of failures in a real tracking system.  For example, such failures might occur with a magnetic tracker near interfering materials, or with visual tracking when tracked features are lost.

In our experiment we vary two parameters: the field of view of the AR interface and the length of tracking failure periods.  Each trial is 60 seconds, with seven tracking failures.  The total vertical field of view of the HMD is 36 degrees; the three possible values for the augmented field of view were 10, 20, and 34 degrees.  The length of tracking failures varied between two seconds (high failure), one second (medium failure) and zero seconds (no failure).  We experimented with longer values but deemed them too long to be realistic through expert analysis.  This gave us a total of 9 conditions, and for each participant we tested each condition 3 times giving a total of 27 trials per participant.

During each trial there are 20 people in addition to a virtual man \emph{Top Hat} wearing a tall black top hat walking an unpredictable path outside of the room.  The paths for each virtual person was randomly generated from set of coordinates exterior to the room.  Each path had the constraint that they must stay within the rectangular $50\times50$ $m^2$ area surrounding the room.  At each path point, the person will randomly change his/her walking speed within the range of 4 to 7 m/s.  \emph{Top Hat} had the additional constraints as follows.  He must start at the same location for each trial which made him visible by the participant through the front door the building.  In order to make the paths by of similar difficulty \emph{Tophat} must walk around the entire building at least once, and he must be visible through the windows for at least 10 seconds.  These constraints were met by randomly generating paths until all were satisfied.  We generated 27 sets of paths in this fashion, each corresponding to a specific trial.  We used a latin squares ordering to discourage the effects of learning.

We implemented this experiment with Python and the Vizard virtual reality toolkit.  Head-tracking was handled by a InterSense InertiaCube3 orientation tracker with a 180 Hz refresh rate.  We used a Pro-View 60 head mounted display (HMD) displaying $640\times480$ video at 60 Hz, and 36 degrees vertical field of view.  As we were not concerned with stereo performance, we turned off the stereoscopic feature.  The experiment ran on a 2.4 GHz Intel Core 2 machine with 2 Gb of RAM and a NVIDIA GeForce 9800 GX2 graphics card running Windows XP SP3.

\begin{figure}[t]
	\centering
	\includegraphics[width=3in]{figures/tophatscreenshot.png}
	\caption{Sample user-view of AR simulation.  \emph{Top Hat} is visible (non-occluded) in the doorway.  The augmented view overlays transparent red rectangles on the characters, indicating their location while occluded.}
\end{figure}

\section{Analysis}

In our experiment we define performance as effectiveness in tracking \emph{Tophat}.  We measure performance by recording the angular distance (in yaw) between the the user's viewing direction and the direction towards the target character.  This measure ranges between zero and 180 degrees (we used the smaller of the two options, clockwise and counter-clockwise).  We record one measurement per video frame, at about sixty frames per second, resulting in about 3600 measurements for a one second trial.

Because the video does not run at exactly 60 Hz, each trial might have a slightly different number of measurements.  We also record a timestamp for each measurement, so that we can determine their exact frequency.  As a pre-processing step, we linearly re-sample the data for each trial so that each has exactly 3600 measurements at 60 Hz.

We observed that participants tend to switch between two different states during the experiment: a tracking state, where they are following the target; and a lost state, where they are searching for the target.  The two states are easily visible in the data.  In the tracking state, the angular error is generally low.  We asked participants to keep the cross hairs on the target as closely as they could, but different participants achieved different levels of accuracy.  In the lost state, the error starts to steadily climb, and may fluctuate depending on where the target moves.  The error may even return to near-zero during a lost state, if the participant unwittingly crosses the target's path.

% TODO: include two plots of error here (one with losses, one without)

We hypothesize that less immersive conditions will have longer and more frequent periods where the participant loses the target.  We considered several different metrics which might be appropriate in testing this hypothesis.

The simplest is the average error over an entire trial.  This may not accurately capture the amount that a participant is lost, because the error does not necessarily stay high during the lost state, and also different participants may generally keep the cross hair further from the target even in the tracking state.

% median ??

We can more explicitly detect the participant's state by applying a threshold $\tau$ to the data.  The threshold specifies the maximum angular error that still represents successful tracking of the target. 
%When the error rises above the threshold, we consider the participant lost.
We use a threshold of one quarter of the total horizontal field of view of the HMD, $\tau = 12$ degrees.
% TODO: how to motivate this threshold?

Using this threshold we measure a participant's ``time to failure,'' the time until the a lost state is encountered.  However, this may not be a very descriptive measure, since a participant may reach the lost state sooner or later depending on the movement of the avatars, which varies between trials.

We also consider a measurement we call ``time tracking,'' which is the amount of time spent in the tracking state.  This metric seems to most generally represent how well a participant performed.  Trials with either more lost periods or longer lost periods will result in a lower total time tracking.

For a more specific measure of performance, we count the number of times a participant reaches the lost state in a trial.  We only record a lost state when the error stays above the threshold $\tau$ for a minimum of 0.5 seconds.
% TODO: how to motivate this threshold?

%time tracking is overview metric -- captures both number of times lost and length of lost periods

%number of times lost is piece of overview -- number of times lost.

\section{Results}

%\begin{figure}[t]
%	\centering
%	\includegraphics[width=3in]{figures/numtimes_deadlen.pdf}
%	\caption{Box plot of the number of times the participant is lost versus the length of the tracking failure periods.}
%\end{figure}

%\begin{figure}[t]
%	\centering
%	\includegraphics[width=3in]{figures/numtimes_fov.pdf}
%	\caption{Box plot of the number of times the participant becomes lost versus the field of view of the augmentations.}
%\end{figure}

%\begin{figure}[t]
%	\centering
%	\includegraphics[width=3in]{figures/numtimes_interaction.pdf}
%	\caption{Interaction plot of the effect of field of view and tracking failure on the number of times the participant becomes lost.}
%\end{figure}

\begin{figure}[t]
	\centering
	\includegraphics[width=3in]{figures/tt_deadlen.pdf}
	\caption{\label{fig:tt_deadlen}Box plot of the amount of time that the target is near the crosshairs versus the length of tracker failure periods.}
\end{figure}

%\begin{figure}[t]
%	\centering
%	\includegraphics[width=3in]{figures/tt_fov.pdf}
%	\caption{Box plot of time the participant is not lost versus the field of view of the augmentations.}
%\end{figure}

%\begin{figure}[t]
%	\centering
%	\includegraphics[width=3in]{figures/numtimes_extra_deadlen.pdf}
%	\caption{Box plot of the number of times the participant is lost versus the length of the tracking failure periods, for the medium field of view condition, including the half second trial.}
%\end{figure}

% TODO: should we include data from older generation??

% TODO: look at analysis from mean.

We performed two-way {ANOVA} for the time tracking metric as an overall analysis of the effects of our two factors.  Table \ref{fig:anova} gives the results of this analysis.  Both the failure length and the field of view had a very significant effect on performance using this metric.  
% TODO: interaction?

% TODO: num times lost: fov not significant, deadlen significant, interaction -- talk about what interaction means.


Figure \ref{fig:tt_deadlen} shows a box plot of time tracking versus failure length.  Performance decreases between zero and one seconds, but seems to level off between one and two.  We ran a post-hoc analysis to determine which conditions were significantly different.  Using Tukey's HSD, we found that conditions one and two were significantly different than zero (p<??), but not significantly different from each other (p<??).  This suggests that we may be seeing a thresholding effect above one second tracking failures.

This suggests that we have reached a threshold at one second.  We had seven participants complete an extra three trials with the medium field of view and tracking failure periods of 0.5 seconds.  Figure 8 shows the data.  There wasn't a significant difference between the zero length and half second length conditions.  For future work, we could find the threshold between 0.5 and 1.

%use multiple comparison of means to determine which pairs are significant -- difference between length of one and length of two is not significant.

\begin{figure}[htb]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
%\multicolumn{2}{|c|}{Selection Stroke Thresholds} \\
Metric & Factor & F value & Pr \\
\hline
Time Tracking & Failure Length & 20.41 & $<0.001$\\
Time Tracking & Field of View & 13.549 & $<0.001$\\
Number of Times Lost & Failure Length & 61.816 & $<0.001$\\
\hline
\end{tabular}
 \caption{\label{fig:anova}Factors which have a significant effect.}
\end{figure}

\section{Conclusions and Future Work}



\section*{Acknowledgements}
Cha Lee, Steffan Gauglitz, funding, and all of our participants.

\bibliographystyle{acmsiggraph}
\nocite{*}
\bibliography{paper}
\end{document}
