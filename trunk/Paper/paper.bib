
%% Created for Jonathan Ventura at 2009-06-22 17:25:42 -0700 


%% Saved with string encoding Unicode (UTF-8) 



@inproceedings{1180501,
	Address = {New York, NY, USA},
	Author = {Wang, Yi and Otitoju, Kunmi and Liu, Tong and Kim, Sijung and Bowman, Doug A.},
	Booktitle = {VRST '06: Proceedings of the ACM symposium on Virtual reality software and technology},
	Date-Added = {2009-06-22 17:25:41 -0700},
	Date-Modified = {2009-06-22 17:25:41 -0700},
	Doi = {http://doi.acm.org/10.1145/1180495.1180501},
	Isbn = {1-59593-321-2},
	Location = {Limassol, Cyprus},
	Pages = {19--26},
	Publisher = {ACM},
	Title = {Evaluating the effects of real world distraction on user performance in virtual environments},
	Year = {2006},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1180495.1180501}}

@inproceedings{1383060,
	Abstract = { This paper presents a set of interactive tools designed to give users virtual x-ray vision. These tools address a common problem in depicting occluded infrastructure: either too much information is displayed, confusing users, or too little information is displayed, depriving users of important depth cues. Four tools are presented: the tunnel tool and room selector tool directly augment the user's view of the environment, allowing them to explore the scene in direct, first person view. The room in miniature tool allows the user to select and interact with a room from a third person perspective, allowing users to view the contents of the room from points of view that would normally be difficult or impossible to achieve. The room slicer tool aids users in exploring volumetric data displayed within the room in miniature tool. Used together, the tools presented in this paper can be used to achieve the virtual x-ray vision effect. We test our prototype system in a far-field mobile augmented reality setup, visualizing the interiors of a small set of buildings on the UCSB campus.},
	Author = {Bane, R. and H\"{o}llerer, T.},
	Booktitle = {Mixed and Augmented Reality, 2004. ISMAR 2004. Third IEEE and ACM International Symposium on},
	Date-Added = {2009-06-10 00:23:18 -0700},
	Date-Modified = {2009-06-10 00:23:45 -0700},
	Doi = {10.1109/ISMAR.2004.36},
	Keywords = {X-ray imaging, augmented reality, computer vision interactive tools, mobile augmented reality, room in miniature tool, room selector tool, room slicer tool, tunnel tool, virtual x-ray vision},
	Month = {Nov.},
	Pages = {231-239},
	Title = {Interactive tools for virtual x-ray vision in mobile augmented reality},
	Year = {2004},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/ISMAR.2004.36}}

@inproceedings{4811058,
	Abstract = {We propose the use of virtual environments to simulate augmented reality (AR) systems for the purposes of experimentation and usability evaluation. This method allows complete control in the AR environment, providing many advantages over testing with true AR systems. We also discuss some of the limitations to the simulation approach. We have demonstrated the use of such a simulation in a proof of concept experiment controlling the levels of registration error in the AR scenario. In this experiment, we used the simulation method to investigate the effects of registration error on task performance for a generic task involving precise motor control for AR object manipulation. Isolating jitter and latency errors, we provide empirical evidence of the relationship between accurate registration and task performance.},
	Author = {Ragan, E. and Wilkes, C. and Bowman, D.A. and Hollerer, T.},
	Booktitle = {Virtual Reality Conference, 2009. VR 2009. IEEE},
	Date-Added = {2009-06-10 00:04:13 -0700},
	Date-Modified = {2009-06-10 00:04:19 -0700},
	Doi = {10.1109/VR.2009.4811058},
	Issn = {1087-8270},
	Journal = {Virtual Reality Conference, 2009. VR 2009. IEEE},
	Keywords = {augmented reality, digital simulationaugmented reality system, motor control, object manipulation, registration error, system simulation, task performance, usability evaluation, virtual environment},
	Month = {March},
	Pages = {287-288},
	Title = {Simulation of Augmented Reality Systems in Purely Virtual Environments},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/VR.2009.4811058}}

@inproceedings{4637329,
	Abstract = {We conducted a user study of the effect of registration error on performance of tracking distant objects in augmented reality. Categorizing error by types that are often used as specifications, we hoped to derive some insight into the ability of users to tolerate noise, latency, and orientation error. We used measurements from actual systems to derive the parameter settings. We expected all three errors to influence userspsila ability to perform the task correctly and the precision with which they performed the task. We found that high latency had a negative impact on both performance and response time. While noise consistently interacted with the other variables, and orientation error increased user error, the differences between ldquohighrdquo and ldquolowrdquo amounts were smaller than we expected. Results of userspsila subjective rankings of these three categories of error were surprisingly mixed. Users believed noise was the most detrimental, though statistical analysis of performance refuted this belief. We interpret the results and draw insights for system design.},
	Author = {Livingston, M.A. and Zhuming Ai},
	Booktitle = {Mixed and Augmented Reality, 2008. ISMAR 2008. 7th IEEE/ACM International Symposium on},
	Date-Added = {2009-06-09 22:41:53 -0700},
	Date-Modified = {2009-06-09 22:42:58 -0700},
	Journal = {Mixed and Augmented Reality, 2008. ISMAR 2008. 7th IEEE/ACM International Symposium on},
	Title = {The effect of registration error on tracking distant augmented objects},
	Year = {2008},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/ISMAR.2008.4637329}}

@misc{azuma95survey,
  author = "R. Azuma",
  title = "A survey of augmented reality",
  text = "Azuma, R. T. A survey of augmented reality. In Computer Graphics (SIGGRAPH
    '95 Proceedings, Course Notes #9: Developing Advanced Virtual Reality Applications)
    (Aug. 1995), pp. 1--38.",
  year = "1995",
  url = "citeseer.ist.psu.edu/azuma95survey.html" }

@INPROCEEDINGS{Livingston02anaugmented,
    author = {Mark A. Livingston and Lawrence J. Rosenblum and Simon J. Julier and Dennis Brown and Yohan Baillot and J. Edward and Swan Ii and Joseph L. Gabbard and Deborah Hix},
    title = {An Augmented Reality System for Military Operations in Urban Terrain},
    booktitle = {In Interservice/Industry Training, Simulation, and Education Conference},
    year = {2002},
    pages = {89}
}

@ARTICLE{1528424,
title={Evaluating human factors in augmented reality systems},
author={Livingston, M.A.},
journal={Computer Graphics and Applications, IEEE},
year={2005},
month={Nov.-Dec.},
volume={25},
number={6},
pages={ 6-9},
keywords={ augmented reality, ergonomics, human factors, user interfaces augmented reality systems, computer graphics methodology, graphical annotations, human factor evaluation, interactive systems, user interface},
doi={10.1109/MCG.2005.130},
ISSN={0272-1716}, }

@INPROCEEDINGS{Webster96augmentedreality,
    author = {Anthony Webster and Steven Feiner and Blair Macintyre and William Massie and Theodore Krueger},
    title = {Augmented Reality in Architectural Construction, Inspection, and Renovation},
    booktitle = {In Proc. ASCE Third Congress on Computing in Civil Engineering},
    year = {1996},
    pages = {913--919}
}

@INPROCEEDINGS{4079263,
title={Going out: robust model-based tracking for outdoor augmented reality},
author={Reitmayr, G. and Drummond, T.W.},
booktitle={Mixed and Augmented Reality, 2006. ISMAR 2006. IEEE/ACM International Symposium on},
year={2006},
month={Oct.},
volume={},
number={},
pages={109-118},
abstract={This paper presents a model-based hybrid tracking system for outdoor augmented reality in urban environments enabling accurate, realtime overlays for a handheld device. The system combines several well-known approaches to provide a robust experience that surpasses each of the individual components alone: an edge-based tracker for accurate localisation, gyroscope measurements to deal with fast motions, measurements of gravity and magnetic field to avoid drift, and a back store of reference frames with online frame selection to re-initialize automatically after dynamic occlusions or failures. A novel edge-based tracker dispenses with the conventional edge model, and uses instead a coarse, but textured, 3D model. This yields several advantages: scale-based detail culling is automatic, appearance-based edge signatures can be used to improve matching and the models needed are more commonly available. The accuracy and robustness of the resulting system is demonstrated with comparisons to map-based ground truth data.},
keywords={augmented reality, edge detection, hidden feature removal, image matching, image texture, solid modelling, tracking3D texture model, accurate localisation, appearance based-line detection, appearance-based edge signature, dynamic occlusion, edge-based tracker, gravity field measurement, gyroscope measurement, handheld device, magnetic field measurement, online frame selection, outdoor augmented reality, point-based image matching, robust model-based hybrid tracking system, scale-based detail culling, urban environment},
doi={10.1109/ISMAR.2006.297801},
ISSN={}, }
